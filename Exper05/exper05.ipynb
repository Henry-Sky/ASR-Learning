{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Henry\\AppData\\Local\\Temp\\ipykernel_11992\\2869324767.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  features = torch.tensor(features).cuda()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "from torch.nn.functional import one_hot\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ASRDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {'features': self.features[idx], 'labels': self.labels[idx]}\n",
    "        return sample\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "files = os.listdir(\"./data/recordings/\")\n",
    "\n",
    "# 读取文件 features: 经过mfcc处理的音频特征, labels: 每个音频的特征标签\n",
    "for file in files:\n",
    "    wave, sr = librosa.load(\"./data/recordings/\"+file)\n",
    "    mfcced_wave = librosa.feature.mfcc(y=wave, sr=sr)\n",
    "    mfcced_wave = np.pad(mfcced_wave, ((0,0),(0,100-mfcced_wave.shape[1])),\n",
    "                        mode='constant', constant_values=0)\n",
    "    features.append(mfcced_wave)\n",
    "    labels.append(int(file[0]))\n",
    "\n",
    "# 数据转移到GPU\n",
    "features = torch.tensor(features).cuda()\n",
    "labels = torch.tensor(labels).cuda()\n",
    "\n",
    "# 对特征进行归一化, 标签转换独热编码\n",
    "mean_features = torch.mean(features, dim=2)\n",
    "std_features = torch.std(features, dim=2)\n",
    "features = features.sub_(mean_features[:,:,None]).div_(std_features[:,:,None])\n",
    "labels = one_hot(labels, 10)\n",
    "\n",
    "# 对 recordings 数据的特征和标签打包并划分训练集,测试集\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, train_size=0.7)\n",
    "train_dataset = ASRDataset(x_train, y_train)\n",
    "test_dataset = ASRDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "\n",
    "class ASRCNN(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super(ASRCNN, self).__init__()\n",
    "\n",
    "        # 卷积层定义\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=config.data_dims,\n",
    "                      out_channels=config.num_filters,\n",
    "                      kernel_size=filter_size)\n",
    "                      for filter_size in config.filter_sizes\n",
    "        ])\n",
    "\n",
    "        # 池化层定义\n",
    "        self.maxpool = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        # 全连接层定义\n",
    "        self.num_filters_total = config.num_filters * len(config.filter_sizes)\n",
    "        self.fc1 = nn.Linear(self.num_filters_total, config.hidden_dim)\n",
    "        self.fc2 = nn.Linear(config.hidden_dim, config.num_classes)\n",
    "\n",
    "        # 神经元保留概率\n",
    "        self.keep_prob = config.keep_prob\n",
    "\n",
    "        # 初始化参数\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for conv_layer in self.conv_layers:\n",
    "            nn.init.xavier_uniform_(conv_layer.weight)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        # 卷积操作\n",
    "        conved_x_list = [func.relu(conv(x)) for conv in self.conv_layers]\n",
    "        # 池化操作\n",
    "        pooled_x_list = [self.maxpool(conved_x) for conved_x in conved_x_list]\n",
    "\n",
    "        conned_x = torch.cat(pooled_x_list, dim=1)\n",
    "        conned_x = conned_x.view(-1,self.num_filters_total)\n",
    "\n",
    "        fc_x = func.relu(self.fc1(conned_x))\n",
    "        fc_x = func.dropout(fc_x, self.keep_prob)\n",
    "\n",
    "        outs = func.softmax(self.fc2(fc_x), dim=1)\n",
    "\n",
    "        return outs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNConfig():\n",
    "    data_dims = 100\n",
    "    filter_sizes = [2, 3, 4, 5]\n",
    "    num_filters = 64\n",
    "    num_classes = 10\n",
    "    hidden_dim = 256\n",
    "    keep_prob = 0.7\n",
    "\n",
    "config = CNNConfig()\n",
    "model = ASRCNN(config).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第10次迭代-模型损失:1.9487; 准确率:51.4555%\n",
      "第20次迭代-模型损失:1.7561; 准确率:67.7226%\n",
      "第30次迭代-模型损失:1.6926; 准确率:73.5445%\n",
      "第40次迭代-模型损失:1.6029; 准确率:81.4212%\n",
      "第50次迭代-模型损失:1.5567; 准确率:83.2192%\n",
      "第60次迭代-模型损失:1.5477; 准确率:85.3596%\n",
      "第70次迭代-模型损失:1.5310; 准确率:85.9589%\n",
      "第80次迭代-模型损失:1.5274; 准确率:88.3562%\n",
      "第90次迭代-模型损失:1.5142; 准确率:87.1575%\n",
      "第100次迭代-模型损失:1.5054; 准确率:88.9555%\n",
      "第110次迭代-模型损失:1.5003; 准确率:88.0993%\n",
      "保存模型\n",
      "第120次迭代-模型损失:1.5011; 准确率:88.8699%\n",
      "第130次迭代-模型损失:1.4901; 准确率:89.7260%\n",
      "第140次迭代-模型损失:1.5297; 准确率:88.6986%\n",
      "保存模型\n",
      "第150次迭代-模型损失:1.4893; 准确率:89.8973%\n",
      "第160次迭代-模型损失:1.4848; 准确率:90.2397%\n",
      "保存模型\n",
      "第170次迭代-模型损失:1.4847; 准确率:90.5822%\n",
      "保存模型\n",
      "第180次迭代-模型损失:1.4836; 准确率:90.2397%\n",
      "保存模型\n",
      "第190次迭代-模型损失:1.4869; 准确率:89.9829%\n",
      "第200次迭代-模型损失:1.4876; 准确率:88.3562%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9)\n",
    "\n",
    "# 模型训练\n",
    "epoch_num = 200\n",
    "\n",
    "max_acc = 0.0\n",
    "for epoch in range(epoch_num):\n",
    "    loss_sum = 0.0\n",
    "    total_batch = 0.0\n",
    "    torch.cuda.empty_cache()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        features, labels = data[\"features\"].cuda(), data[\"labels\"].cuda()\n",
    "        features, labels = features.float(), labels.float()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model.forward(features)\n",
    "        # 默认为单批次损失的均值\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss_sum += loss.item()\n",
    "        total_batch += 1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_mean = loss_sum / total_batch\n",
    "\n",
    "    correct_sum = 0.0\n",
    "    total = 0.0\n",
    "    torch.cuda.empty_cache()\n",
    "    for data in test_loader:\n",
    "        features, labels = data[\"features\"].cuda(), data[\"labels\"].cuda()\n",
    "        features, labels = features.float(), labels.float()\n",
    "        with torch.no_grad():\n",
    "            outputs = model.forward(features)\n",
    "            _, predicts = torch.max(outputs, 1)\n",
    "            _, labels = torch.max(labels, 1)\n",
    "            correct_sum += (predicts == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    acc_mean = correct_sum / total * 100\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(\"第{}次迭代-模型损失:{:.4f}; 准确率:{:.4f}%\".format(epoch+1, loss_mean, acc_mean))\n",
    "\n",
    "    if acc_mean > 90.0 and acc_mean > max_acc:\n",
    "        max_acc = acc_mean\n",
    "        print(\"保存模型\")\n",
    "        torch.save(model.state_dict(),'./data/models/ASRCNN_{}.rui'.format(acc_mean))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
